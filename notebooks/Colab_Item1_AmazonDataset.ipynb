{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dadosfera Case — Item 1 (Colab)\n",
        "## Baixar e preparar o dataset **Amazon Reviews (Electronics)** localmente\n",
        "\n",
        "Este notebook faz:\n",
        "- download do `reviews_Electronics_5.json.gz` (SNAP/Stanford)\n",
        "- leitura incremental (JSON Lines)\n",
        "- limpeza mínima / tipagem\n",
        "- salvamento em **Parquet**\n",
        "\n",
        "> Data: 2026-01-03\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip -q install pandas pyarrow requests tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Rodrigo\\Desktop\\py\\Prjt\\DDF_TECH_122025\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os, json, gzip, math, requests\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "DATA_DIR = Path(\"data\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "DATASET_URL = \"https://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\"\n",
        "RAW_GZ_PATH = DATA_DIR / \"reviews_Electronics_5.json.gz\"\n",
        "\n",
        "# Controle de volume (para rodar rápido no Colab)\n",
        "# - O dataset completo é bem grande; para o case, >=100k já atende.\n",
        "MAX_ROWS = 400_000   # ajuste se quiser (ex: 100_000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Download do dataset (SNAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baixando: https://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 496M/496M [00:38<00:00, 12.8MB/s] \n"
          ]
        }
      ],
      "source": [
        "def download_file(url: str, dest: Path, chunk_size: int = 1024 * 1024):\n",
        "    if dest.exists() and dest.stat().st_size > 0:\n",
        "        print(f\"Arquivo já existe: {dest} ({dest.stat().st_size/1e6:.1f} MB)\")\n",
        "        return\n",
        "\n",
        "    print(f\"Baixando: {url}\")\n",
        "    with requests.get(url, stream=True, timeout=60) as r:\n",
        "        r.raise_for_status()\n",
        "        total = int(r.headers.get(\"content-length\", 0))\n",
        "        with open(dest, \"wb\") as f, tqdm(total=total, unit=\"B\", unit_scale=True) as pbar:\n",
        "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "\n",
        "download_file(DATASET_URL, RAW_GZ_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Leitura incremental do `.json.gz` (JSON Lines)\n",
        "\n",
        "Vamos ler até `MAX_ROWS` para acelerar o desenvolvimento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linhas: 400000\n",
            "Colunas: ['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText', 'overall', 'summary', 'unixReviewTime', 'reviewTime']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AO94DHGC771SJ</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>amazdnu</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Gotta have GPS!</td>\n",
              "      <td>1370131200</td>\n",
              "      <td>06 2, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AMO214LNFCEI4</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>[12, 15]</td>\n",
              "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Very Disappointed</td>\n",
              "      <td>1290643200</td>\n",
              "      <td>11 25, 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A3N7T0DY83Y4IG</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>C. A. Freeman</td>\n",
              "      <td>[43, 45]</td>\n",
              "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1st impression</td>\n",
              "      <td>1283990400</td>\n",
              "      <td>09 9, 2010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID        asin     reviewerName   helpful  \\\n",
              "0   AO94DHGC771SJ  0528881469          amazdnu    [0, 0]   \n",
              "1   AMO214LNFCEI4  0528881469  Amazon Customer  [12, 15]   \n",
              "2  A3N7T0DY83Y4IG  0528881469    C. A. Freeman  [43, 45]   \n",
              "\n",
              "                                          reviewText  overall  \\\n",
              "0  We got this GPS for my husband who is an (OTR)...      5.0   \n",
              "1  I'm a professional OTR truck driver, and I bou...      1.0   \n",
              "2  Well, what can I say.  I've had this unit in m...      3.0   \n",
              "\n",
              "             summary  unixReviewTime   reviewTime  \n",
              "0    Gotta have GPS!      1370131200   06 2, 2013  \n",
              "1  Very Disappointed      1290643200  11 25, 2010  \n",
              "2     1st impression      1283990400   09 9, 2010  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def read_gz_json_lines(path: Path, max_rows: int | None = None):\n",
        "    rows = []\n",
        "    with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if max_rows is not None and i >= max_rows:\n",
        "                break\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            rows.append(json.loads(line))\n",
        "    return rows\n",
        "\n",
        "data = read_gz_json_lines(RAW_GZ_PATH, max_rows=MAX_ROWS)\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Linhas:\", len(df))\n",
        "print(\"Colunas:\", list(df.columns))\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Preparação mínima (colunas principais + tipagem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>helpful</th>\n",
              "      <th>review_datetime</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>helpful_up</th>\n",
              "      <th>helpful_total</th>\n",
              "      <th>reviewText_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AO94DHGC771SJ</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Gotta have GPS!</td>\n",
              "      <td>1370131200</td>\n",
              "      <td>06 2, 2013</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>2013-06-02</td>\n",
              "      <td>2013</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AMO214LNFCEI4</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Very Disappointed</td>\n",
              "      <td>1290643200</td>\n",
              "      <td>11 25, 2010</td>\n",
              "      <td>[12, 15]</td>\n",
              "      <td>2010-11-25</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>2175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A3N7T0DY83Y4IG</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1st impression</td>\n",
              "      <td>1283990400</td>\n",
              "      <td>09 9, 2010</td>\n",
              "      <td>[43, 45]</td>\n",
              "      <td>2010-09-09</td>\n",
              "      <td>2010</td>\n",
              "      <td>9</td>\n",
              "      <td>43</td>\n",
              "      <td>45</td>\n",
              "      <td>4607</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID        asin  \\\n",
              "0   AO94DHGC771SJ  0528881469   \n",
              "1   AMO214LNFCEI4  0528881469   \n",
              "2  A3N7T0DY83Y4IG  0528881469   \n",
              "\n",
              "                                          reviewText  overall  \\\n",
              "0  We got this GPS for my husband who is an (OTR)...      5.0   \n",
              "1  I'm a professional OTR truck driver, and I bou...      1.0   \n",
              "2  Well, what can I say.  I've had this unit in m...      3.0   \n",
              "\n",
              "             summary  unixReviewTime   reviewTime   helpful review_datetime  \\\n",
              "0    Gotta have GPS!      1370131200   06 2, 2013    [0, 0]      2013-06-02   \n",
              "1  Very Disappointed      1290643200  11 25, 2010  [12, 15]      2010-11-25   \n",
              "2     1st impression      1283990400   09 9, 2010  [43, 45]      2010-09-09   \n",
              "\n",
              "   year  month  helpful_up  helpful_total  reviewText_len  \n",
              "0  2013      6           0              0             805  \n",
              "1  2010     11          12             15            2175  \n",
              "2  2010      9          43             45            4607  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Colunas mais úteis do dataset\n",
        "wanted_cols = [\n",
        "    \"reviewerID\", \"asin\", \"reviewText\", \"overall\", \"summary\",\n",
        "    \"unixReviewTime\", \"reviewTime\", \"helpful\"\n",
        "]\n",
        "cols = [c for c in wanted_cols if c in df.columns]\n",
        "df = df[cols].copy()\n",
        "\n",
        "# Tipagem\n",
        "if \"overall\" in df.columns:\n",
        "    df[\"overall\"] = pd.to_numeric(df[\"overall\"], errors=\"coerce\")\n",
        "\n",
        "if \"unixReviewTime\" in df.columns:\n",
        "    df[\"review_datetime\"] = pd.to_datetime(df[\"unixReviewTime\"], unit=\"s\", errors=\"coerce\")\n",
        "    df[\"year\"] = df[\"review_datetime\"].dt.year\n",
        "    df[\"month\"] = df[\"review_datetime\"].dt.month\n",
        "\n",
        "# Helpful geralmente é [upvotes, total]\n",
        "if \"helpful\" in df.columns:\n",
        "    df[\"helpful_up\"] = df[\"helpful\"].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None)\n",
        "    df[\"helpful_total\"] = df[\"helpful\"].apply(lambda x: x[1] if isinstance(x, list) and len(x) > 1 else None)\n",
        "\n",
        "# Higiene simples\n",
        "if \"reviewText\" in df.columns:\n",
        "    df[\"reviewText_len\"] = df[\"reviewText\"].astype(str).str.len()\n",
        "\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Salvar como Parquet (para ingestão e performance)\n",
        "\n",
        "Vamos salvar o dataset preparado e uma amostra menor para testes rápidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Salvo: data\\electronics_reviews_prepared.parquet -> 164.936579 MB\n",
            "Salvo: data\\electronics_reviews_sample_50k.parquet -> 21.731382 MB\n"
          ]
        }
      ],
      "source": [
        "OUT_PARQUET = DATA_DIR / \"electronics_reviews_prepared.parquet\"\n",
        "OUT_SAMPLE = DATA_DIR / \"electronics_reviews_sample_50k.parquet\"\n",
        "\n",
        "df.to_parquet(OUT_PARQUET, index=False)\n",
        "\n",
        "# Amostra (para dev rápido)\n",
        "sample = df.sample(min(50_000, len(df)), random_state=42) if len(df) > 0 else df\n",
        "sample.to_parquet(OUT_SAMPLE, index=False)\n",
        "\n",
        "print(\"Salvo:\", OUT_PARQUET, \"->\", OUT_PARQUET.stat().st_size/1e6, \"MB\")\n",
        "print(\"Salvo:\", OUT_SAMPLE, \"->\", OUT_SAMPLE.stat().st_size/1e6, \"MB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Checagens rápidas\n",
        "\n",
        "- confirmar `>= 100k` linhas\n",
        "- ver distribuição de rating (1–5)\n",
        "- nulos principais\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rows': 400000, 'null_reviewText_pct': 0.0, 'null_overall_pct': 0.0}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assert len(df) >= 100_000, f\"Dataset com {len(df)} linhas; precisa >=100k para o case.\"\n",
        "\n",
        "checks = {\n",
        "    \"rows\": len(df),\n",
        "    \"null_reviewText_pct\": float(df[\"reviewText\"].isna().mean()) if \"reviewText\" in df.columns else None,\n",
        "    \"null_overall_pct\": float(df[\"overall\"].isna().mean()) if \"overall\" in df.columns else None,\n",
        "}\n",
        "checks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "if \"overall\" in df.columns:\n",
        "    df[\"overall\"].value_counts(dropna=False).sort_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6454757e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arquivo gerado com sucesso: 150000\n"
          ]
        }
      ],
      "source": [
        "# carrega o parquet\n",
        "df_googleSheets = pd.read_parquet(r\"C:\\Users\\Rodrigo\\Desktop\\py\\Prjt\\DDF_TECH_122025\\notebooks\\data\\electronics_reviews_prepared.parquet\")\n",
        "\n",
        "# amostra representativa\n",
        "df_150k = df_googleSheets.sample(150_000, random_state=42)\n",
        "\n",
        "# exporta para CSV (compatível com Google Sheets)\n",
        "df_150k.to_csv(\n",
        "    \"amazon_reviews_electronics_150k.csv\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(\"Arquivo gerado com sucesso:\", len(df_150k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b1120f87",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Rodrigo\\Desktop\\py\\Prjt\\DDF_TECH_122025\\notebooks\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d3f46990",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pastas no projeto:\n",
            "['.git', '.gitignore', 'Data', 'docs', 'gen_ai_insight.py', 'Images_and_files', 'notebooks', 'README_v2.md', 'requirements.txt', 'scripts', 'venv']\n"
          ]
        }
      ],
      "source": [
        "base = r\"C:\\Users\\Rodrigo\\Desktop\\py\\Prjt\\DDF_TECH_122025\"\n",
        "print(\"Pastas no projeto:\")\n",
        "print(os.listdir(base))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "42b05063",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110000\n"
          ]
        }
      ],
      "source": [
        "df_100k = df_googleSheets.sample(110_000, random_state=42)\n",
        "\n",
        "df_100k.to_csv(\n",
        "    \"amazon_reviews_electronics_110k.csv\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(len(df_100k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd3d13e",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Dadosfera_Item1_AmazonDataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
