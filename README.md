# Case T√©cnico Dadosfera - Rodrigo Assarice
**Cargo:** Engenheiro de Dados (Candidato)

## üìå Vis√£o Geral do Projeto
Este reposit√≥rio cont√©m a resolu√ß√£o do Case T√©cnico da Dadosfera, simulando uma opera√ß√£o completa de dados ponta a ponta para um ecossistema de e-commerce. O objetivo √© demonstrar profici√™ncia em ingest√£o, cataloga√ß√£o, qualidade, modelagem dimensional, IA Generativa e visualiza√ß√£o.

---

## üîó Links r√°pidos ‚Äì Ativos do projeto

### Pipelines
- **Amazon Reviews_DDF_TECH_122025_v2**  
  https://app.dadosfera.ai/pt-BR/collect/pipelines/ee124bd6-b4f2-47db-8a19-00739509e01e

### Dados Curados / DW
- **PUBLIC.DW__FATO_REVIEWS_ENRIQUECIDA**  
  https://app.dadosfera.ai/pt-BR/catalog/data-assets/f6033cf6-b16c-4df1-9f67-3872af98892a

### Cat√°logo de Dados
- **PUBLIC.PUBLIC__ELECTRONICS_REVIEWS**  
  *(TB__BYTSNO__PUBLIC__ELECTRONICS_REVIEWS)*  
  https://app.dadosfera.ai/pt-BR/catalog/data-assets/b6409229-a9e6-45ea-878c-911811e1e65c

### Visualiza√ß√µes / BI
- **Amazon Reviews (Dadosfera)**  
  https://app.dadosfera.ai/pt-BR/catalog/data-assets/aa7be233-88a9-4f5d-ad3b-9fba4dad77df
- **Amazon Reviews (Metabase)**  
  https://metabase-treinamentos.dadosfera.ai/dashboard/236-amazon-reviews
  
---

## üìù Nota sobre a escolha do dataset

Para este case, foi utilizado o dataset de reviews da Amazon (Electronics) com o objetivo de demonstrar o uso de IA generativa e t√©cnicas de enriquecimento sem√¢ntico aplicadas a dados textuais n√£o estruturados.

Em um cen√°rio real de e-commerce, √© comum que an√°lises estrat√©gicas envolvam tamb√©m dados transacionais (pedidos, clientes, log√≠stica). No entanto, o pipeline, a modelagem e as an√°lises desenvolvidas neste projeto s√£o diretamente aplic√°veis a bases transacionais, mantendo a mesma l√≥gica arquitetural e anal√≠tica.

A escolha deste dataset permitiu explorar, de forma mais aprofundada, capacidades t√©cnicas relacionadas a processamento de linguagem natural, gera√ß√£o de features e integra√ß√£o de IA generativa, atendendo aos objetivos propostos no case.

---

### üìä Cronograma Detalhado (Gantt)

| Atividade | Hr 1 | Hr 2 | Hr 5 | Hr 8 | Hr10 | Hr11 | Status |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :--- |
| **0 e 1: Funda√ß√£o e Base de Dados** | üü¶ | | | | | | ‚úÖ |
| **2.1 e 3: Ingest√£o e Cataloga√ß√£o** | | üü¶ | | | | | ‚úÖ |
| **4 e 5: Qualidade e GenAI** | | | üü¶ | | | | ‚úÖ |
| **6 e 7: Modelagem e Pipelines** | | | | üü¶ | | | ‚úÖ |
| **8: Pipelines com spark** | | | | üü¶ | | | üìÖ |
| **7 e 9: BI e Data App (Streamlit)** | | | | | üü¶ | | ‚úÖ |
| **10: Entrega e V√≠deo** | | | | | | üü¶ | üìÖ |

*Legenda: üü¶ Per√≠odo de execu√ß√£o | ‚úÖ Conclu√≠do | üïí Em Progresso | üìÖ Agendado*

## üìÖ Item 0: Planejamento (Horas)

### Cronograma de Execu√ß√£o

| Dia | Fase | Atividade Principal | Itens Relacionados |
| :--- | :--- | :--- | :--- |
| **Hr 1** | **Ingest√£o** | Setup, Escolha do Dataset e Carga inicial | Item 1, 2.1 |
| **Hr 2** | **Cat√°logo** | Cria√ß√£o do Dicion√°rio de Dados e Explora√ß√£o | Item2.1, Item 3 |
| **Hr 5** | **Qualidade** | Relat√≥rios de Data Quality (Great Expectations) | Item 4 |
| **Hr 6** | **Intelig√™ncia** | Processamento com GenAI e LLMs | Item 5 |
| **Hr 8** | **Arquitetura** | Modelagem Star Schema e Dashboards | Item 6, 7 |
| **Hr 10** | **Entrega** | Finaliza√ß√£o BI, Data App Streamlit  | Item 9|

### Quadro Kanban do Projeto

| A FAZER (Backlog) | EM ANDAMENTO | CONCLU√çDO |
| :--- | :--- | :--- |
| Item 10: Pitch Final (V√≠deo) | Item 8: Pipeline de Dados | Item 0: Planejamento ‚úÖ |
|  | | Item 2.1: Ingest√£o na Dadosfera ‚úÖ |
|  | |Item 3: Cat√°logo de Dados ‚úÖ |
|  | |Item 4: Data Quality ‚úÖ |
|  | |Item 5: GenAI & LLM ‚úÖ |
|  | |Item 6: Modelagem Star Schema ‚úÖ |
|  | |Item 7: Dashboard de BI ‚úÖ |
|  | |Item 9: Data App (Streamlit) ‚úÖ |


---

## üìä Detalhamento dos Itens do Case

### Item 1: Base de Dados Selecionada
## üì¶ Dataset Escolhido ‚Äî Amazon Reviews (Electronics)

- **Fonte:** Stanford SNAP ‚Äì Amazon Product Reviews  
- **Dom√≠nio:** E-commerce  
- **Volume:** ~400.000 registros  
- **Granularidade:** 1 linha por review  

Principais campos:
- `reviewerID` ‚Äî identificador do usu√°rio  
- `asin` ‚Äî identificador do produto  
- `overall` ‚Äî avalia√ß√£o (1 a 5)  
- `reviewText` ‚Äî texto da avalia√ß√£o  
- `review_datetime` ‚Äî data da review  
- `year`, `month` ‚Äî atributos temporais  

A prepara√ß√£o inicial do dataset foi realizada em ambiente externo, utilizando **Google Colab** e **Python**, com o objetivo de validar volume, estrutura e qualidade dos dados antes da ingest√£o definitiva na plataforma Dadosfera.

### Notebook utilizado
- `notebooks/Colab_Item1_AmazonDataset.ipynb`

### Principais atividades
- Download do dataset bruto (`.json.gz`)
- Leitura incremental controlada por volume
- Sele√ß√£o e tipagem das colunas relevantes
- Gera√ß√£o de arquivos no formato **Parquet**
- Valida√ß√£o de volume m√≠nimo (>100.000 registros)

Sa√≠da principal:
- `electronics_reviews_prepared.parquet`


## üîó Item 2 ‚Äî Sobre a Dadosfera: Integrar (Collect)

Ap√≥s a prepara√ß√£o dos dados, o dataset foi persistido em uma **fonte estruturada PostgreSQL (Neon)**, utilizada como **sistema fonte externo** para a plataforma Dadosfera.

### Processo de integra√ß√£o
- Cria√ß√£o de uma conex√£o PostgreSQL no m√≥dulo **Collect**
- Configura√ß√£o de carga **Full Load**
- Execu√ß√£o da pipeline de ingest√£o
- Valida√ß√£o da carga com sucesso

üì∏ **Pipeline de Coleta ‚Äì Collect**  
![Pipeline Collect](pipeline_Dados.jpg)
A imagem faz referencia a pipeline de dados realizada.

## üîç Item 3 ‚Äî Sobre a Dadosfera: Explorar e Catalogar

Os dados ingeridos foram posicionados na **Landing Zone**, camada de ingest√£o (*Raw*) da arquitetura de Data Lake da Dadosfera.

Ap√≥s a ingest√£o, o dataset foi automaticamente disponibilizado no m√≥dulo **Explorar (Cat√°logo)**, onde foram registrados metadados relevantes, seguindo boas pr√°ticas de **Dicion√°rio de Dados**.

üì∏ **Dataset Catalogado na Dadosfera**  
![Cat√°logo Dadosfera](pv_catalogo.jpg)
A imagem acima representa o catalogo de dados referenciado na plataforma.


Al√©m disso, foi utilizado o notebook:
- `notebooks/Governanca_Amazon_Reviews.ipynb`

## üß™ Item 4 ‚Äî Qualidade dos Dados
Com o objetivo de avaliar a qualidade do dataset Amazon Reviews (Electronics) ingerido na plataforma Dadosfera, foram realizadas verifica√ß√µes de Data Quality com foco explorat√≥rio, seguindo boas pr√°ticas adotadas em pipelines de Engenharia de Dados.

As an√°lises tiveram como finalidade garantir que os dados estivessem aptos para consumo anal√≠tico, al√©m de documentar poss√≠veis inconsist√™ncias antes de etapas futuras de processamento.

## üîç Dimens√µes de Qualidade Avaliadas

As seguintes dimens√µes de qualidade foram consideradas:
Completude: verifica√ß√£o da presen√ßa de valores nulos nas colunas do dataset.
Validade: checagem da conformidade dos dados em rela√ß√£o a dom√≠nios esperados.
Consist√™ncia: avalia√ß√£o da coer√™ncia entre colunas relacionadas.
Conformidade: ader√™ncia ao schema inferido durante a ingest√£o.

## üõ†Ô∏è Metodologia Utilizada

As verifica√ß√µes foram executadas por meio de um notebook explorat√≥rio, utilizando:
Great Expectations (API Pandas legacy) para regras de completude e validade.
Regras customizadas em pandas para valida√ß√µes espec√≠ficas de consist√™ncia entre colunas.
O notebook utilizado encontra-se em:
notebooks/DataQuality_Amazon_Reviews_Soda_GE.ipynb

## ‚úÖ Regras de Qualidade Implementadas

Completude
Verifica√ß√£o da aus√™ncia de valores nulos em colunas obrigat√≥rias como asin e reviewerID.
Validade
overall com valores entre 1 e 5.
month com valores entre 1 e 12.
year dentro de um intervalo temporal v√°lido.
Consist√™ncia
Regra garantindo que helpful_up seja sempre menor ou igual a helpful_total, validada por meio de uma checagem customizada em pandas.

## üìä Resultados Obtidos

As valida√ß√µes n√£o indicaram falhas cr√≠ticas de qualidade:
O dataset apresentou alta completude, sem valores nulos.
Os campos num√©ricos respeitaram os dom√≠nios definidos.
N√£o foram encontradas viola√ß√µes na regra de consist√™ncia entre helpful_up e helpful_total.
As evid√™ncias geradas foram exportadas nos seguintes formatos:
data_quality_report.csv ‚Äî relat√≥rio consolidado das valida√ß√µes.
ge_validation_results.json ‚Äî resultado detalhado das execu√ß√µes do Great Expectations.
Esses arquivos permitem rastreabilidade e reprodutibilidade das an√°lises realizadas.

As verifica√ß√µes de qualidade indicam que o dataset est√° adequado para uso anal√≠tico e para etapas posteriores do ciclo de dados na plataforma Dadosfera.
Em um cen√°rio produtivo, essas regras poderiam ser automatizadas por meio de pipelines no m√≥dulo de Intelig√™ncia da Dadosfera, possibilitando monitoramento cont√≠nuo e alertas em caso de desvios.

## ü§ñ Item 5 ‚Äî Uso de LLMs e Explica√ß√£o do Prompt

Objetivo do uso de LLMs
O objetivo desta etapa foi demonstrar a capacidade de transformar dados textuais desestruturados em features estruturadas, utilizando modelos de linguagem (LLMs), possibilitando an√°lises qualitativas e agrega√ß√µes anal√≠ticas que n√£o seriam vi√°veis apenas com dados num√©ricos.
Foram utilizados textos de reviews de produtos, que representam dados n√£o estruturados, extra√≠dos do dataset.

Desenho da Solu√ß√£o com LLM
O processo foi implementado em um notebook explorat√≥rio, executado localmente, seguindo as seguintes etapas:

1 - Sele√ß√£o de uma amostra representativa de reviews do dataset.
2 - Constru√ß√£o de um prompt estruturado, orientado √† extra√ß√£o de informa√ß√µes espec√≠ficas.
3 - Envio do texto ao modelo de linguagem (LLM) via API.
4 - Recebimento da resposta em formato JSON estruturado.
5 - Organiza√ß√£o das features extra√≠das em um dataset anal√≠tico.

Essa abordagem permite validar o potencial do uso de LLMs para enriquecimento sem√¢ntico dos dados, sem necessidade de processamento em larga escala.

Constru√ß√£o e Explica√ß√£o do Prompt

O prompt foi desenhado de forma determin√≠stica e orientada √† tarefa, com o objetivo de reduzir ambiguidades e garantir consist√™ncia nas respostas.

You are a data extraction assistant.

Extract structured features in STRICT JSON with the following fields:
- sentiment (positive, neutral, negative)
- main_topics (array of strings)
- product_quality (good, average, poor)
- usability (easy, medium, hard)
- short_summary (one concise sentence)

Text:
"{review_text}"

Justificativa do Prompt

Contexto claro: o modelo √© instru√≠do a atuar como um assistente de extra√ß√£o de dados.
Formato de sa√≠da expl√≠cito: a exig√™ncia de JSON garante que a resposta seja diretamente consum√≠vel por pipelines anal√≠ticos.
Campos bem definidos:
sentiment: captura a polaridade emocional do texto.
main_topics: identifica os principais aspectos mencionados.
product_quality: infere a percep√ß√£o de qualidade do produto.
usability: avalia a facilidade de uso percebida.
short_summary: gera um resumo sem√¢ntico conciso.
Essa defini√ß√£o permite transformar texto livre em features padronizadas e reutiliz√°veis.

Execu√ß√£o do Modelo de Linguagem

Foi utilizado um modelo de linguagem da OpenAI (GPT) por meio de chamadas via API, com retorno for√ßado em formato JSON, garantindo consist√™ncia e facilidade de parsing.
Para fins de controle de custo e tempo de execu√ß√£o, o processamento foi realizado sobre uma amostra de 25 reviews, sendo suficiente para demonstrar o funcionamento da abordagem.

## Resultado da Gera√ß√£o de Features

A sa√≠da do modelo consiste em um conjunto de atributos estruturados, por exemplo:
{
  "sentiment": "positive",
  "main_topics": ["MMO gaming", "user experience"],
  "product_quality": "good",
  "usability": "easy",
  "short_summary": "The product enhances the gaming experience for MMO players."
}
Essas features podem ser utilizadas em an√°lises agregadas, dashboards, modelos anal√≠ticos ou enriquecimento de dados em pipelines futuros.

O uso de LLMs demonstrado neste item evidencia como dados desestruturados podem ser convertidos em informa√ß√£o estruturada de alto valor anal√≠tico.
Em um ambiente produtivo, esse processo poderia ser automatizado e integrado a pipelines de processamento cont√≠nuo, respeitando requisitos de custo, governan√ßa e escalabilidade.

### üß± Item 6 ‚Äî Modelagem de Dados

## Abordagem: Modelo Dimensional (Kimball)

Foi adotado o modelo dimensional de Kimball devido aos seguintes fatores:
 - O dataset possui natureza anal√≠tica e hist√≥rica.
 - O principal objetivo √© an√°lise de avalia√ß√µes, produtos e comportamento de usu√°rios.
 - A plataforma √© orientada a consumo anal√≠tico, dashboards e relat√≥rios.
 - O modelo dimensional oferece:
   - simplicidade de entendimento;
   - alto desempenho para consultas;
   - f√°cil integra√ß√£o com ferramentas de BI.

üëâ Abordagens como Data Vault seriam mais adequadas a cen√°rios de m√∫ltiplas fontes operacionais e alta complexidade, o que n√£o √© o caso deste dataset.

Uma linha da tabela fato representa uma review de um produto feita por um usu√°rio em uma data espec√≠fica.
Garantir:
    - consist√™ncia;
    - possibilidade de agrega√ß√µes temporais;
    - an√°lise por produto, usu√°rio e sentimento.

## üìê Estrutura do Data Warehouse Proposto
   # üîπ Tabela Fato
    FATO_REVIEWS
    Campo	        Descri√ß√£o
    review_id	    Identificador da review
    asin	        Identificador do produto
    reviewer_id	    Identificador do usu√°rio
    date_id	        Chave da dimens√£o tempo
    overall	        Nota num√©rica da review
    sentiment	    Sentimento extra√≠do via LLM
    product_quality	Qualidade inferida
    usability	    Facilidade de uso
    helpful_up	    Votos positivos
    helpful_total	Total de votos
    review_text_len	Tamanho do texto
    review_count	M√©trica derivada (1)

   # üîπ Dimens√µes
    DIM_PRODUTO
    Campo	            Descri√ß√£o
    asin	            Chave do produto
    product_category	Categoria do produto
    product_title	    T√≠tulo
    product_description	Descri√ß√£o

    DIM_USUARIO
    Campo	            Descri√ß√£o
    reviewer_id	        Identificador do usu√°rio
    reviewer_segment	Segmenta√ß√£o derivada
    activity_level	    N√≠vel de atividade

    DIM_TEMPO
    Campo	Descri√ß√£o
    date_id	Chave da data
    date	Data completa
    year	Ano
    month	M√™s
    day	    Dia
    weekday	Dia da semana

## Vis√£o 1 ‚Äî Performance de Produtos
    Objetivo: analisar a percep√ß√£o dos produtos ao longo do tempo.
    Exemplo de m√©tricas:
        - m√©dia de avalia√ß√£o (overall);
        - distribui√ß√£o de sentimentos;
        - volume de reviews por produto;
        - engajamento (helpful_up).
    Consumo t√≠pico:
        - dashboards executivos
        - ranking de produtos

## Vis√£o 2 ‚Äî Comportamento dos Usu√°rios
    Objetivo: entender padr√µes de usu√°rios e engajamento.
    Exemplo de m√©tricas:
        - n√∫mero de reviews por usu√°rio;
        - m√©dia de avalia√ß√µes dadas;
        - padr√£o de sentimentos;
        - usu√°rios mais ativos.
    Consumo t√≠pico:
        - an√°lises de comportamento
        - segmenta√ß√£o de usu√°rios

## Camadas do DW 
    A modelagem proposta se encaixa naturalmente nas camadas finais do Data Lake / DW:
        - Landing Zone: dados brutos ingeridos.
        - Standardized Zone: dados tipados e normalizados.
        - Curated Zone: modelo dimensional (fato + dimens√µes).
        - Consumption Layer: vis√µes anal√≠ticas e dashboards.

## Modelo Dimensional (Star Schema)
![Modelo Dimensional - Star Schema](modelagem.jpg)
A imagem acima representa o modelo dimensional proposto, seguindo o padr√£o Star Schema, com a tabela fato de reviews no centro e suas dimens√µes associadas.


### üìä Item 7 ‚Äî An√°lise de Dados: Dashboard e Consultas no Metabase
Objetivo da An√°lise

O objetivo dessa an√°lise foi criar um dashboard interativo utilizando o Metabase, com base no dataset Amazon Reviews (Electronics). As an√°lises focaram em m√©tricas de avalia√ß√£o, votos √∫teis, tamanho das avalia√ß√µes e comportamento dos usu√°rios. Essas m√©tricas s√£o cruciais para entender como os usu√°rios interagem com os produtos e como as avalia√ß√µes evoluem ao longo do tempo.

Processo no Metabase
Sele√ß√£o de Dados:
Utilizando a tabela dw.fato_reviews_enriquecida e a tabela dw.dw_dim_tempo que cont√©m informa√ß√µes sobre as avalia√ß√µes dos produtos que os usu√°rios realizaram, e informa√ß√µes adicionais como votos √∫teis, alem das datas da dimens√£o tempo.

Consultas e Visualiza√ß√µes Criadas:
As consultas SQL foram feitas para gerar m√©tricas como:
Distribui√ß√£o das Avalia√ß√µes (Overall)por cliente: Analisando como as avalia√ß√µes dos produtos s√£o distribu√≠das ao longo das notas de 1 a 5.
Impacto das avalia√ß√µes com base no descritivo dos reviews.
Engajamento dos Usu√°rios (Helpful Up/Total): Mostrando a quantidade de votos √∫teis recebidos para cada produto.
An√°lise Temporal: Visualizando a evolu√ß√£o das avalia√ß√µes ao longo do tempo, por ano e m√™s.
Tamanho das Avalia√ß√µes: Analisando a m√©dia e a mediana do tamanho das avalia√ß√µes de acordo com o tempo e a qualidade do produto.
Mediana do review agrupando por ano.

Nesta entrega, a etapa de enriquecimento via LLM foi demonstrada por amostragem (25 reviews) para validar o desenho da solu√ß√£o e o schema de features, considerando restri√ß√µes de custo/tempo. Em cen√°rio produtivo, a estrat√©gia seria escalonar via batch ass√≠ncrono e/ou processamento incremental com controle de custos e monitoramento.

Gr√°ficos e Resultados:
No Metabase, criei gr√°ficos de:
Distribui√ß√£o de Votos (Gr√°fico de barras).
Votos √öteis ao Longo do Tempo (Gr√°fico de linha).
M√©dia de Tamanho de Avalia√ß√£o (Gr√°fico de barras com linha).
Compara√ß√£o de Qualidade do Produto e Tamanho da Avalia√ß√£o.
An√°lise de Avalia√ß√µes por Produto (Gr√°fico de barras).

![Dash Meta](Item7.jpg)
A imagem faz referencia a visualiza√ß√£o de dados geradas no meta.

### Consultas SQL (exemplos)
```sql
SELECT  date_trunc('month', date_id) AS mes,
        COUNT(*) AS total_reviews,
        AVG(overall) AS media_rating
FROM dw.fato_reviews_enriquecida
GROUP BY 1
ORDER BY 1;

SELECT sentiment,
       COUNT(*) AS qtd
FROM dw.fato_reviews_enriquecida
WHERE sentiment IS NOT NULL
GROUP BY sentiment
ORDER BY qtd DESC;

SELECT product_id,
       COUNT(*) AS qtd_reviews,
       AVG(overall) AS avg_rating
FROM dw.fato_reviews_enriquecida
GROUP BY product_id
ORDER BY qtd_reviews DESC
LIMIT 10;


SELECT date_trunc('month', date_id) AS mes,
       AVG(overall) AS media_rating
FROM dw.fato_reviews_enriquecida
GROUP BY mes
ORDER BY mes;

SELECT reviewtext_len,
       overall
FROM dw.fato_reviews_enriquecida
WHERE reviewtext_len IS NOT NULL AND overall IS NOT NULL;
```

### 8. Processamento de Dados com PySpark para Neon PostgreSQL (escopo demonstrativo)

No Item 8 do case, o objetivo era criar um pipeline de dados para processar as avalia√ß√µes de produtos da Amazon e integr√°-las com o Neon PostgreSQL. Implementar o PySpark para realizar o processamento dos dados e a  pipeline de extra√ß√£o, transforma√ß√£o e carga (ETL).

- `notebooks/PySpark_to_Neon_Integration.ipynb`

### Item 9 Sobre Data Apps
Similaridade entre Produtos: Utiliza o TF-IDF e cosine similarity para identificar produtos similares com base nas descri√ß√µes das avalia√ß√µes.
An√°lise Explorat√≥ria de Dados (EDA): Realiza uma an√°lise descritiva dos dados, incluindo gr√°ficos de distribui√ß√£o de avalia√ß√µes, comprimento das avalia√ß√µes e matriz de correla√ß√£o.
Visualiza√ß√µes Interativas: O app gera gr√°ficos interativos utilizando Seaborn e Matplotlib, permitindo uma explora√ß√£o visual detalhada dos dados.

Tecnologias Utilizadas
Streamlit: Framework para criar aplica√ß√µes web interativas e visualiza√ß√µes de dados.
pandas: Manipula√ß√£o de dados tabulares.
sklearn: C√°lculo de similaridade entre produtos.
Seaborn e Matplotlib: Cria√ß√£o de gr√°ficos e visualiza√ß√µes.

## ‚ñ∂Ô∏è Como executar o Data App (Streamlit)

Pr√©-requisitos:
- Python 3.9+
- Ambiente virtual (opcional)

Passos:
pip install -r requirements.txt
streamlit run data_apps/app.py
Observa√ß√£o:
O app utiliza dados previamente processados e tem car√°ter demonstrativo para o case t√©cnico.


---

## üõ†Ô∏è Tecnologias Utilizadas
- **Linguagens:** SQL e Python
- **IA:** OpenAI API / GenAI
- **Frameworks:** Streamlit, Great Expectations

## üìÅ Estrutura do Reposit√≥rio
```
DDF_TECH_122025/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ pipeline_Dados.jpg
‚îú‚îÄ‚îÄ pv_catalogo.jpg
‚îú‚îÄ‚îÄ governanca_.jpg
‚îú‚îÄ‚îÄ modelagem.jpg
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ Colab_Item1_AmazonDataset.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ Upload_Parquet_to_Neon_Postgres.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ Governanca_Amazon_Reviews.ipynb
|   ‚îú‚îÄ‚îÄ DataQuality_Amazon_Reviews_Soda_GE.ipynb
|   ‚îî‚îÄ‚îÄ Item5_GenAI_Feature_Engineering.ipynb
‚îú‚îÄ‚îÄ data_apps/
|   ‚îî‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ governanca/
|   ‚îú‚îÄ‚îÄ data_quality_report.csv
|   ‚îú‚îÄ‚îÄ dicionario_dados.csv
|   ‚îú‚îÄ‚îÄ ge_validation_results.json
|   ‚îî‚îÄ‚îÄ governanca_relatorio.md
```

---

## ‚úÖ Status do Case

- ‚úî Item 1 ‚Äî Base de Dados  
- ‚úî Item 2 ‚Äî Integra√ß√£o (Collect)  
- ‚úî Item 3 ‚Äî Sobre a Dadosfera: Explorar e Catalogar
- ‚úî Item 4 ‚Äî Qualidade dos Dados
- ‚úî Item 5 ‚Äî Uso de LLMs e Explica√ß√£o do Prompt (Limitado pelo uso de tokens)
- ‚úî Item 6 ‚Äî Modelagem de Dados
- ‚úî Item 7 ‚Äî An√°lise de Dados: Dashboard e Consultas no Metabase
- ‚úî Item 9 ‚Äî Sobre Data Apps











